{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXJOMGwxRpYT"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "glVmy-hxRubs",
        "outputId": "780da385-61b3-4cec-c51c-2e6165843fc2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9b82fece-4bbb-43f0-9937-378731d047f3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9b82fece-4bbb-43f0-9937-378731d047f3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"lesszxd\",\"key\":\"4e8e2decc2ead2e03c25c800f4d71c1f\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP9PjKPIR3sv"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en00fE4HSBkj"
      },
      "outputs": [],
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF-VTlYySNkO"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8uytSz8SdUp",
        "outputId": "d2dfb277-0227-414d-e5a2-7e1a737fa216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                                   title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "arnabchaki/data-science-salaries-2023                                 Data Science Salaries 2023 💸                         25KB  2023-04-13 09:55:16          32549        885  1.0              \n",
            "tawfikelmetwally/automobile-dataset                                   Car information dataset                               6KB  2023-05-28 18:26:48           3975        114  0.9411765        \n",
            "fatihb/coffee-quality-data-cqi                                        Coffee Quality Data (CQI May-2023)                   22KB  2023-05-12 13:06:39           6113        128  1.0              \n",
            "mohithsairamreddy/salary-data                                         Salary_Data                                          17KB  2023-05-18 14:05:19           6239        123  0.88235295       \n",
            "mauryansshivam/netflix-ott-revenue-and-subscribers-csv-file           Netflix OTT Revenue and Subscribers (CSV File)        2KB  2023-05-13 17:40:23           2997         67  1.0              \n",
            "omarsobhy14/mcdonalds-revenue                                         🍟💰From Flipping Burgers to Billions: McDonald's      565B  2023-06-01 23:22:49            726         32  1.0              \n",
            "drahulsingh/list-of-best-selling-ps4-games                            List of best-selling PlayStation 4 video games        2KB  2023-06-11 17:36:59            941         30  1.0              \n",
            "zsinghrahulk/rice-pest-and-diseases                                   Rice - Pest and Diseases                            312KB  2023-06-01 08:57:29            785         31  1.0              \n",
            "iammustafatz/diabetes-prediction-dataset                              Diabetes prediction dataset                         734KB  2023-04-08 06:11:45          16995        247  1.0              \n",
            "vstacknocopyright/fruit-and-vegetable-prices                          Fruit and Vegetable Prices                            1KB  2023-06-02 06:17:43           1274         36  0.7647059        \n",
            "goyaladi/iit-admissions-dataset                                       IIT Admissions Dataset - 200,000 Students             5MB  2023-06-16 09:31:48            825         22  1.0              \n",
            "bilalwaseer/microsoft-stocks-from-1986-to-2023                        Microsoft Stocks from 1986 to 2023                  120KB  2023-05-16 10:07:28           1153         33  1.0              \n",
            "bhanupratapbiswas/fashion-products                                    Fashion Products                                     20KB  2023-06-12 03:56:26            841         34  0.7058824        \n",
            "darshanprabhu09/stock-prices-for                                      Stock prices of Amazon , Microsoft , Google, Apple   85KB  2023-05-16 15:17:16           2272         50  1.0              \n",
            "rajkumarpandey02/2023-world-population-by-country                      World Population by Country                         38KB  2023-06-01 06:10:41           2295         42  1.0              \n",
            "danishjmeo/karachi-housing-prices-2023                                Karachi_Housing_Prices_2023                           1MB  2023-06-01 07:08:13            589         30  0.9411765        \n",
            "adityaramachandran27/world-air-quality-index-by-city-and-coordinates  World Air Quality Index by City and Coordinates     372KB  2023-05-07 07:29:26           2342         49  1.0              \n",
            "dansbecker/melbourne-housing-snapshot                                 Melbourne Housing Snapshot                          451KB  2018-06-05 12:52:24         118194       1286  0.7058824        \n",
            "pushpakhinglaspure/oscar-dataset                                      Oscar Academy Award-winning films 1927-2022         161KB  2023-05-21 18:14:44            969         34  1.0              \n",
            "aryansingh0909/weekly-patent-application-granted                      Patent Application Granted Dataset                    6MB  2023-06-01 19:04:40            448         25  1.0              \n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd1bv4NBSkH2",
        "outputId": "5ce553cc-7403-4e33-9176-4c46e5193a2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading bisindo-letter-dataset.zip to /content\n",
            "100% 20.4M/20.4M [00:00<00:00, 92.2MB/s]\n",
            "100% 20.4M/20.4M [00:00<00:00, 80.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d alfredolorentiars/bisindo-letter-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUyEsIqRTpq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c5143f-2b19-4617-ff93-242b35a46b31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  bisindo-letter-dataset.zip\n",
            "  inflating: BISINDO/A/A (1).jpg     \n",
            "  inflating: BISINDO/A/A (10).jpg    \n",
            "  inflating: BISINDO/A/A (11).jpg    \n",
            "  inflating: BISINDO/A/A (12).jpg    \n",
            "  inflating: BISINDO/A/A (2).jpg     \n",
            "  inflating: BISINDO/A/A (3).jpg     \n",
            "  inflating: BISINDO/A/A (4).jpg     \n",
            "  inflating: BISINDO/A/A (5).jpg     \n",
            "  inflating: BISINDO/A/A (6).jpg     \n",
            "  inflating: BISINDO/A/A (7).jpg     \n",
            "  inflating: BISINDO/A/A (8).jpg     \n",
            "  inflating: BISINDO/A/A (9).jpg     \n",
            "  inflating: BISINDO/A/A 1.png       \n",
            "  inflating: BISINDO/A/A 10.png      \n",
            "  inflating: BISINDO/A/A 11.png      \n",
            "  inflating: BISINDO/A/A 12.png      \n",
            "  inflating: BISINDO/A/A 2.png       \n",
            "  inflating: BISINDO/A/A 3.png       \n",
            "  inflating: BISINDO/A/A 4.png       \n",
            "  inflating: BISINDO/A/A 5.png       \n",
            "  inflating: BISINDO/A/A 6.png       \n",
            "  inflating: BISINDO/A/A 7.png       \n",
            "  inflating: BISINDO/A/A 8.png       \n",
            "  inflating: BISINDO/A/A 9.png       \n",
            "  inflating: BISINDO/A/A_13.png      \n",
            "  inflating: BISINDO/A/A_14.png      \n",
            "  inflating: BISINDO/A/A_15.png      \n",
            "  inflating: BISINDO/A/A_16.png      \n",
            "  inflating: BISINDO/A/A_17.png      \n",
            "  inflating: BISINDO/A/A_18.png      \n",
            "  inflating: BISINDO/A/A_19.png      \n",
            "  inflating: BISINDO/A/A_20.png      \n",
            "  inflating: BISINDO/A/A_21.png      \n",
            "  inflating: BISINDO/A/A_22.png      \n",
            "  inflating: BISINDO/A/A_23.png      \n",
            "  inflating: BISINDO/A/A_24.png      \n",
            "  inflating: BISINDO/B/B (1).jpg     \n",
            "  inflating: BISINDO/B/B (10).jpg    \n",
            "  inflating: BISINDO/B/B (11).jpg    \n",
            "  inflating: BISINDO/B/B (12).jpg    \n",
            "  inflating: BISINDO/B/B (2).jpg     \n",
            "  inflating: BISINDO/B/B (3).jpg     \n",
            "  inflating: BISINDO/B/B (4).jpg     \n",
            "  inflating: BISINDO/B/B (5).jpg     \n",
            "  inflating: BISINDO/B/B (6).jpg     \n",
            "  inflating: BISINDO/B/B (7).jpg     \n",
            "  inflating: BISINDO/B/B (8).jpg     \n",
            "  inflating: BISINDO/B/B (9).jpg     \n",
            "  inflating: BISINDO/B/B 1.png       \n",
            "  inflating: BISINDO/B/B 10.png      \n",
            "  inflating: BISINDO/B/B 11.png      \n",
            "  inflating: BISINDO/B/B 12.png      \n",
            "  inflating: BISINDO/B/B 13.png      \n",
            "  inflating: BISINDO/B/B 14.png      \n",
            "  inflating: BISINDO/B/B 15.png      \n",
            "  inflating: BISINDO/B/B 2.png       \n",
            "  inflating: BISINDO/B/B 3.png       \n",
            "  inflating: BISINDO/B/B 7.png       \n",
            "  inflating: BISINDO/B/B 8.png       \n",
            "  inflating: BISINDO/B/B 9.png       \n",
            "  inflating: BISINDO/B/B_13.png      \n",
            "  inflating: BISINDO/B/B_14.png      \n",
            "  inflating: BISINDO/B/B_15.png      \n",
            "  inflating: BISINDO/B/B_16.png      \n",
            "  inflating: BISINDO/B/B_17.png      \n",
            "  inflating: BISINDO/B/B_18.png      \n",
            "  inflating: BISINDO/B/B_19.png      \n",
            "  inflating: BISINDO/B/B_20.png      \n",
            "  inflating: BISINDO/B/B_21.png      \n",
            "  inflating: BISINDO/B/B_22.png      \n",
            "  inflating: BISINDO/B/B_23.png      \n",
            "  inflating: BISINDO/B/B_24.png      \n",
            "  inflating: BISINDO/C/C (1).jpg     \n",
            "  inflating: BISINDO/C/C (10).jpg    \n",
            "  inflating: BISINDO/C/C (11).jpg    \n",
            "  inflating: BISINDO/C/C (12).jpg    \n",
            "  inflating: BISINDO/C/C (2).jpg     \n",
            "  inflating: BISINDO/C/C (3).jpg     \n",
            "  inflating: BISINDO/C/C (4).jpg     \n",
            "  inflating: BISINDO/C/C (5).jpg     \n",
            "  inflating: BISINDO/C/C (6).jpg     \n",
            "  inflating: BISINDO/C/C (7).jpg     \n",
            "  inflating: BISINDO/C/C (8).jpg     \n",
            "  inflating: BISINDO/C/C (9).jpg     \n",
            "  inflating: BISINDO/C/C 1.png       \n",
            "  inflating: BISINDO/C/C 10.png      \n",
            "  inflating: BISINDO/C/C 11.png      \n",
            "  inflating: BISINDO/C/C 12.png      \n",
            "  inflating: BISINDO/C/C 13.png      \n",
            "  inflating: BISINDO/C/C 14.png      \n",
            "  inflating: BISINDO/C/C 15.png      \n",
            "  inflating: BISINDO/C/C 2.png       \n",
            "  inflating: BISINDO/C/C 3.png       \n",
            "  inflating: BISINDO/C/C 7.png       \n",
            "  inflating: BISINDO/C/C 8.png       \n",
            "  inflating: BISINDO/C/C 9.png       \n",
            "  inflating: BISINDO/C/C_13.png      \n",
            "  inflating: BISINDO/C/C_14.png      \n",
            "  inflating: BISINDO/C/C_15.png      \n",
            "  inflating: BISINDO/C/C_16.png      \n",
            "  inflating: BISINDO/C/C_17.png      \n",
            "  inflating: BISINDO/C/C_18.png      \n",
            "  inflating: BISINDO/C/C_19.png      \n",
            "  inflating: BISINDO/C/C_20.png      \n",
            "  inflating: BISINDO/C/C_21.png      \n",
            "  inflating: BISINDO/C/C_22.png      \n",
            "  inflating: BISINDO/C/C_23.png      \n",
            "  inflating: BISINDO/C/C_24.png      \n",
            "  inflating: BISINDO/D/D (1).jpg     \n",
            "  inflating: BISINDO/D/D (10).jpg    \n",
            "  inflating: BISINDO/D/D (11).jpg    \n",
            "  inflating: BISINDO/D/D (12).jpg    \n",
            "  inflating: BISINDO/D/D (2).jpg     \n",
            "  inflating: BISINDO/D/D (3).jpg     \n",
            "  inflating: BISINDO/D/D (4).jpg     \n",
            "  inflating: BISINDO/D/D (5).jpg     \n",
            "  inflating: BISINDO/D/D (6).jpg     \n",
            "  inflating: BISINDO/D/D (7).jpg     \n",
            "  inflating: BISINDO/D/D (8).jpg     \n",
            "  inflating: BISINDO/D/D (9).jpg     \n",
            "  inflating: BISINDO/D/D 1.png       \n",
            "  inflating: BISINDO/D/D 10.png      \n",
            "  inflating: BISINDO/D/D 11.png      \n",
            "  inflating: BISINDO/D/D 12.png      \n",
            "  inflating: BISINDO/D/D 13.png      \n",
            "  inflating: BISINDO/D/D 14.png      \n",
            "  inflating: BISINDO/D/D 15.png      \n",
            "  inflating: BISINDO/D/D 2.png       \n",
            "  inflating: BISINDO/D/D 3.png       \n",
            "  inflating: BISINDO/D/D 7.png       \n",
            "  inflating: BISINDO/D/D 8.png       \n",
            "  inflating: BISINDO/D/D 9.png       \n",
            "  inflating: BISINDO/D/D_13.png      \n",
            "  inflating: BISINDO/D/D_14.png      \n",
            "  inflating: BISINDO/D/D_15.png      \n",
            "  inflating: BISINDO/D/D_16.png      \n",
            "  inflating: BISINDO/D/D_17.png      \n",
            "  inflating: BISINDO/D/D_18.png      \n",
            "  inflating: BISINDO/D/D_19.png      \n",
            "  inflating: BISINDO/D/D_20.png      \n",
            "  inflating: BISINDO/D/D_21.png      \n",
            "  inflating: BISINDO/D/D_22.png      \n",
            "  inflating: BISINDO/D/D_23.png      \n",
            "  inflating: BISINDO/D/D_24.png      \n",
            "  inflating: BISINDO/E/E (1).jpg     \n",
            "  inflating: BISINDO/E/E (10).jpg    \n",
            "  inflating: BISINDO/E/E (11).jpg    \n",
            "  inflating: BISINDO/E/E (12).jpg    \n",
            "  inflating: BISINDO/E/E (2).jpg     \n",
            "  inflating: BISINDO/E/E (3).jpg     \n",
            "  inflating: BISINDO/E/E (4).jpg     \n",
            "  inflating: BISINDO/E/E (5).jpg     \n",
            "  inflating: BISINDO/E/E (6).jpg     \n",
            "  inflating: BISINDO/E/E (7).jpg     \n",
            "  inflating: BISINDO/E/E (8).jpg     \n",
            "  inflating: BISINDO/E/E (9).jpg     \n",
            "  inflating: BISINDO/E/E 1.png       \n",
            "  inflating: BISINDO/E/E 10.png      \n",
            "  inflating: BISINDO/E/E 11.png      \n",
            "  inflating: BISINDO/E/E 12.png      \n",
            "  inflating: BISINDO/E/E 13.png      \n",
            "  inflating: BISINDO/E/E 14.png      \n",
            "  inflating: BISINDO/E/E 15.png      \n",
            "  inflating: BISINDO/E/E 2.png       \n",
            "  inflating: BISINDO/E/E 3.png       \n",
            "  inflating: BISINDO/E/E 7.png       \n",
            "  inflating: BISINDO/E/E 8.png       \n",
            "  inflating: BISINDO/E/E 9.png       \n",
            "  inflating: BISINDO/E/E_16.png      \n",
            "  inflating: BISINDO/E/E_17.jpg      \n",
            "  inflating: BISINDO/E/E_17.png      \n",
            "  inflating: BISINDO/E/E_18.png      \n",
            "  inflating: BISINDO/E/E_19.png      \n",
            "  inflating: BISINDO/E/E_20.png      \n",
            "  inflating: BISINDO/E/E_21.png      \n",
            "  inflating: BISINDO/E/E_22.png      \n",
            "  inflating: BISINDO/E/E_23.png      \n",
            "  inflating: BISINDO/E/E_24.png      \n",
            "  inflating: BISINDO/E/E_25.png      \n",
            "  inflating: BISINDO/E/E_26.png      \n",
            "  inflating: BISINDO/F/F (1).jpg     \n",
            "  inflating: BISINDO/F/F (10).jpg    \n",
            "  inflating: BISINDO/F/F (11).jpg    \n",
            "  inflating: BISINDO/F/F (12).jpg    \n",
            "  inflating: BISINDO/F/F (2).jpg     \n",
            "  inflating: BISINDO/F/F (3).jpg     \n",
            "  inflating: BISINDO/F/F (4).jpg     \n",
            "  inflating: BISINDO/F/F (5).jpg     \n",
            "  inflating: BISINDO/F/F (6).jpg     \n",
            "  inflating: BISINDO/F/F (7).jpg     \n",
            "  inflating: BISINDO/F/F (8).jpg     \n",
            "  inflating: BISINDO/F/F (9).jpg     \n",
            "  inflating: BISINDO/F/F 1.png       \n",
            "  inflating: BISINDO/F/F 10.png      \n",
            "  inflating: BISINDO/F/F 11.png      \n",
            "  inflating: BISINDO/F/F 12.png      \n",
            "  inflating: BISINDO/F/F 13.png      \n",
            "  inflating: BISINDO/F/F 14.png      \n",
            "  inflating: BISINDO/F/F 15.png      \n",
            "  inflating: BISINDO/F/F 2.png       \n",
            "  inflating: BISINDO/F/F 3.png       \n",
            "  inflating: BISINDO/F/F 7.png       \n",
            "  inflating: BISINDO/F/F 8.png       \n",
            "  inflating: BISINDO/F/F 9.png       \n",
            "  inflating: BISINDO/F/F_16.png      \n",
            "  inflating: BISINDO/F/F_17.png      \n",
            "  inflating: BISINDO/F/F_18.png      \n",
            "  inflating: BISINDO/F/F_19.png      \n",
            "  inflating: BISINDO/F/F_20.png      \n",
            "  inflating: BISINDO/F/F_21.png      \n",
            "  inflating: BISINDO/F/F_22.png      \n",
            "  inflating: BISINDO/F/F_23.png      \n",
            "  inflating: BISINDO/F/F_24.png      \n",
            "  inflating: BISINDO/F/F_25.png      \n",
            "  inflating: BISINDO/F/F_26.png      \n",
            "  inflating: BISINDO/F/F_27.png      \n",
            "  inflating: BISINDO/G/G (1).jpg     \n",
            "  inflating: BISINDO/G/G (10).jpg    \n",
            "  inflating: BISINDO/G/G (11).jpg    \n",
            "  inflating: BISINDO/G/G (12).jpg    \n",
            "  inflating: BISINDO/G/G (2).jpg     \n",
            "  inflating: BISINDO/G/G (3).jpg     \n",
            "  inflating: BISINDO/G/G (4).jpg     \n",
            "  inflating: BISINDO/G/G (5).jpg     \n",
            "  inflating: BISINDO/G/G (6).jpg     \n",
            "  inflating: BISINDO/G/G (7).jpg     \n",
            "  inflating: BISINDO/G/G (8).jpg     \n",
            "  inflating: BISINDO/G/G (9).jpg     \n",
            "  inflating: BISINDO/G/G 1.png       \n",
            "  inflating: BISINDO/G/G 10.png      \n",
            "  inflating: BISINDO/G/G 11.png      \n",
            "  inflating: BISINDO/G/G 12.png      \n",
            "  inflating: BISINDO/G/G 13.png      \n",
            "  inflating: BISINDO/G/G 14.png      \n",
            "  inflating: BISINDO/G/G 15.png      \n",
            "  inflating: BISINDO/G/G 16.png      \n",
            "  inflating: BISINDO/G/G 2.png       \n",
            "  inflating: BISINDO/G/G 3.png       \n",
            "  inflating: BISINDO/G/G 7.png       \n",
            "  inflating: BISINDO/G/G 8.png       \n",
            "  inflating: BISINDO/G/G 9.png       \n",
            "  inflating: BISINDO/G/G_17.png      \n",
            "  inflating: BISINDO/G/G_18.png      \n",
            "  inflating: BISINDO/G/G_19.png      \n",
            "  inflating: BISINDO/G/G_20.png      \n",
            "  inflating: BISINDO/G/G_21.png      \n",
            "  inflating: BISINDO/G/G_22.png      \n",
            "  inflating: BISINDO/G/G_23.png      \n",
            "  inflating: BISINDO/G/G_24.png      \n",
            "  inflating: BISINDO/G/G_25.png      \n",
            "  inflating: BISINDO/G/G_26.png      \n",
            "  inflating: BISINDO/G/G_27.png      \n",
            "  inflating: BISINDO/H/H (1).jpg     \n",
            "  inflating: BISINDO/H/H (10).jpg    \n",
            "  inflating: BISINDO/H/H (11).jpg    \n",
            "  inflating: BISINDO/H/H (12).jpg    \n",
            "  inflating: BISINDO/H/H (2).jpg     \n",
            "  inflating: BISINDO/H/H (3).jpg     \n",
            "  inflating: BISINDO/H/H (4).jpg     \n",
            "  inflating: BISINDO/H/H (5).jpg     \n",
            "  inflating: BISINDO/H/H (6).jpg     \n",
            "  inflating: BISINDO/H/H (7).jpg     \n",
            "  inflating: BISINDO/H/H (8).jpg     \n",
            "  inflating: BISINDO/H/H (9).jpg     \n",
            "  inflating: BISINDO/H/H 1.png       \n",
            "  inflating: BISINDO/H/H 10.png      \n",
            "  inflating: BISINDO/H/H 11.png      \n",
            "  inflating: BISINDO/H/H 12.png      \n",
            "  inflating: BISINDO/H/H 13.png      \n",
            "  inflating: BISINDO/H/H 14.png      \n",
            "  inflating: BISINDO/H/H 15.png      \n",
            "  inflating: BISINDO/H/H 17.png      \n",
            "  inflating: BISINDO/H/H 18.png      \n",
            "  inflating: BISINDO/H/H 19.png      \n",
            "  inflating: BISINDO/H/H 2.png       \n",
            "  inflating: BISINDO/H/H 21.png      \n",
            "  inflating: BISINDO/H/H 22.png      \n",
            "  inflating: BISINDO/H/H 23.png      \n",
            "  inflating: BISINDO/H/H 24.png      \n",
            "  inflating: BISINDO/H/H 25.png      \n",
            "  inflating: BISINDO/H/H 26.png      \n",
            "  inflating: BISINDO/H/H 27.png      \n",
            "  inflating: BISINDO/H/H 3.png       \n",
            "  inflating: BISINDO/H/H 7.png       \n",
            "  inflating: BISINDO/H/H 8.png       \n",
            "  inflating: BISINDO/H/H 9.png       \n",
            "  inflating: BISINDO/H/H_16(1).png   \n",
            "  inflating: BISINDO/H/H_16.png      \n",
            "  inflating: BISINDO/I/I (1).jpg     \n",
            "  inflating: BISINDO/I/I (10).jpg    \n",
            "  inflating: BISINDO/I/I (11).jpg    \n",
            "  inflating: BISINDO/I/I (12).jpg    \n",
            "  inflating: BISINDO/I/I (2).jpg     \n",
            "  inflating: BISINDO/I/I (3).jpg     \n",
            "  inflating: BISINDO/I/I (4).jpg     \n",
            "  inflating: BISINDO/I/I (5).jpg     \n",
            "  inflating: BISINDO/I/I (6).jpg     \n",
            "  inflating: BISINDO/I/I (7).jpg     \n",
            "  inflating: BISINDO/I/I (8).jpg     \n",
            "  inflating: BISINDO/I/I (9).jpg     \n",
            "  inflating: BISINDO/I/I 1.png       \n",
            "  inflating: BISINDO/I/I 10.png      \n",
            "  inflating: BISINDO/I/I 11.png      \n",
            "  inflating: BISINDO/I/I 12.png      \n",
            "  inflating: BISINDO/I/I 13.png      \n",
            "  inflating: BISINDO/I/I 14.png      \n",
            "  inflating: BISINDO/I/I 15.png      \n",
            "  inflating: BISINDO/I/I 16.png      \n",
            "  inflating: BISINDO/I/I 17.png      \n",
            "  inflating: BISINDO/I/I 18.png      \n",
            "  inflating: BISINDO/I/I 19.png      \n",
            "  inflating: BISINDO/I/I 2.png       \n",
            "  inflating: BISINDO/I/I 20.png      \n",
            "  inflating: BISINDO/I/I 21.png      \n",
            "  inflating: BISINDO/I/I 22.png      \n",
            "  inflating: BISINDO/I/I 23.png      \n",
            "  inflating: BISINDO/I/I 25.png      \n",
            "  inflating: BISINDO/I/I 26.png      \n",
            "  inflating: BISINDO/I/I 27.png      \n",
            "  inflating: BISINDO/I/I 28.png      \n",
            "  inflating: BISINDO/I/I 3.png       \n",
            "  inflating: BISINDO/I/I 7.png       \n",
            "  inflating: BISINDO/I/I 8.png       \n",
            "  inflating: BISINDO/I/I 9.png       \n",
            "  inflating: BISINDO/J/J (1).jpg     \n",
            "  inflating: BISINDO/J/J (10).jpg    \n",
            "  inflating: BISINDO/J/J (11).jpg    \n",
            "  inflating: BISINDO/J/J (12).jpg    \n",
            "  inflating: BISINDO/J/J (2).jpg     \n",
            "  inflating: BISINDO/J/J (3).jpg     \n",
            "  inflating: BISINDO/J/J (4).jpg     \n",
            "  inflating: BISINDO/J/J (5).jpg     \n",
            "  inflating: BISINDO/J/J (6).jpg     \n",
            "  inflating: BISINDO/J/J (7).jpg     \n",
            "  inflating: BISINDO/J/J (8).jpg     \n",
            "  inflating: BISINDO/J/J (9).jpg     \n",
            "  inflating: BISINDO/J/J 1.png       \n",
            "  inflating: BISINDO/J/J 10.png      \n",
            "  inflating: BISINDO/J/J 11.png      \n",
            "  inflating: BISINDO/J/J 12.png      \n",
            "  inflating: BISINDO/J/J 13.png      \n",
            "  inflating: BISINDO/J/J 14.png      \n",
            "  inflating: BISINDO/J/J 15.png      \n",
            "  inflating: BISINDO/J/J 16.png      \n",
            "  inflating: BISINDO/J/J 17.png      \n",
            "  inflating: BISINDO/J/J 18.png      \n",
            "  inflating: BISINDO/J/J 19.png      \n",
            "  inflating: BISINDO/J/J 2.png       \n",
            "  inflating: BISINDO/J/J 20.png      \n",
            "  inflating: BISINDO/J/J 21.png      \n",
            "  inflating: BISINDO/J/J 22.png      \n",
            "  inflating: BISINDO/J/J 23.png      \n",
            "  inflating: BISINDO/J/J 24.png      \n",
            "  inflating: BISINDO/J/J 25.png      \n",
            "  inflating: BISINDO/J/J 26.png      \n",
            "  inflating: BISINDO/J/J 27.png      \n",
            "  inflating: BISINDO/J/J 3.png       \n",
            "  inflating: BISINDO/J/J 7.png       \n",
            "  inflating: BISINDO/J/J 8.png       \n",
            "  inflating: BISINDO/J/J 9.png       \n",
            "  inflating: BISINDO/K/K (1).jpg     \n",
            "  inflating: BISINDO/K/K (10).jpg    \n",
            "  inflating: BISINDO/K/K (11).jpg    \n",
            "  inflating: BISINDO/K/K (12).jpg    \n",
            "  inflating: BISINDO/K/K (2).jpg     \n",
            "  inflating: BISINDO/K/K (3).jpg     \n",
            "  inflating: BISINDO/K/K (4).jpg     \n",
            "  inflating: BISINDO/K/K (5).jpg     \n",
            "  inflating: BISINDO/K/K (6).jpg     \n",
            "  inflating: BISINDO/K/K (7).jpg     \n",
            "  inflating: BISINDO/K/K (8).jpg     \n",
            "  inflating: BISINDO/K/K (9).jpg     \n",
            "  inflating: BISINDO/K/K 1.png       \n",
            "  inflating: BISINDO/K/K 10.png      \n",
            "  inflating: BISINDO/K/K 11.png      \n",
            "  inflating: BISINDO/K/K 12.png      \n",
            "  inflating: BISINDO/K/K 13.png      \n",
            "  inflating: BISINDO/K/K 14.png      \n",
            "  inflating: BISINDO/K/K 15.png      \n",
            "  inflating: BISINDO/K/K 16.png      \n",
            "  inflating: BISINDO/K/K 17.png      \n",
            "  inflating: BISINDO/K/K 18.png      \n",
            "  inflating: BISINDO/K/K 19.png      \n",
            "  inflating: BISINDO/K/K 2.png       \n",
            "  inflating: BISINDO/K/K 20.png      \n",
            "  inflating: BISINDO/K/K 21.png      \n",
            "  inflating: BISINDO/K/K 22.png      \n",
            "  inflating: BISINDO/K/K 23.png      \n",
            "  inflating: BISINDO/K/K 24.png      \n",
            "  inflating: BISINDO/K/K 25.png      \n",
            "  inflating: BISINDO/K/K 26.png      \n",
            "  inflating: BISINDO/K/K 27.png      \n",
            "  inflating: BISINDO/K/K 3.png       \n",
            "  inflating: BISINDO/K/K 7.png       \n",
            "  inflating: BISINDO/K/K 8.png       \n",
            "  inflating: BISINDO/K/K 9.png       \n",
            "  inflating: BISINDO/L/L (1).jpg     \n",
            "  inflating: BISINDO/L/L (10).jpg    \n",
            "  inflating: BISINDO/L/L (11).jpg    \n",
            "  inflating: BISINDO/L/L (12).jpg    \n",
            "  inflating: BISINDO/L/L (2).jpg     \n",
            "  inflating: BISINDO/L/L (3).jpg     \n",
            "  inflating: BISINDO/L/L (4).jpg     \n",
            "  inflating: BISINDO/L/L (5).jpg     \n",
            "  inflating: BISINDO/L/L (6).jpg     \n",
            "  inflating: BISINDO/L/L (7).jpg     \n",
            "  inflating: BISINDO/L/L (8).jpg     \n",
            "  inflating: BISINDO/L/L (9).jpg     \n",
            "  inflating: BISINDO/L/L 1.png       \n",
            "  inflating: BISINDO/L/L 10.png      \n",
            "  inflating: BISINDO/L/L 11.png      \n",
            "  inflating: BISINDO/L/L 12.png      \n",
            "  inflating: BISINDO/L/L 13.png      \n",
            "  inflating: BISINDO/L/L 14.png      \n",
            "  inflating: BISINDO/L/L 15.png      \n",
            "  inflating: BISINDO/L/L 16.png      \n",
            "  inflating: BISINDO/L/L 17.png      \n",
            "  inflating: BISINDO/L/L 18.png      \n",
            "  inflating: BISINDO/L/L 19.png      \n",
            "  inflating: BISINDO/L/L 2.png       \n",
            "  inflating: BISINDO/L/L 20.png      \n",
            "  inflating: BISINDO/L/L 21.png      \n",
            "  inflating: BISINDO/L/L 22.png      \n",
            "  inflating: BISINDO/L/L 23.png      \n",
            "  inflating: BISINDO/L/L 24.png      \n",
            "  inflating: BISINDO/L/L 25.png      \n",
            "  inflating: BISINDO/L/L 26.png      \n",
            "  inflating: BISINDO/L/L 27.png      \n",
            "  inflating: BISINDO/L/L 3.png       \n",
            "  inflating: BISINDO/L/L 7.png       \n",
            "  inflating: BISINDO/L/L 8.png       \n",
            "  inflating: BISINDO/L/L 9.png       \n",
            "  inflating: BISINDO/M/M (1).jpg     \n",
            "  inflating: BISINDO/M/M (10).jpg    \n",
            "  inflating: BISINDO/M/M (11).jpg    \n",
            "  inflating: BISINDO/M/M (12).jpg    \n",
            "  inflating: BISINDO/M/M (2).jpg     \n",
            "  inflating: BISINDO/M/M (3).jpg     \n",
            "  inflating: BISINDO/M/M (4).jpg     \n",
            "  inflating: BISINDO/M/M (5).jpg     \n",
            "  inflating: BISINDO/M/M (6).jpg     \n",
            "  inflating: BISINDO/M/M (7).jpg     \n",
            "  inflating: BISINDO/M/M (8).jpg     \n",
            "  inflating: BISINDO/M/M (9).jpg     \n",
            "  inflating: BISINDO/M/M 1.png       \n",
            "  inflating: BISINDO/M/M 10.png      \n",
            "  inflating: BISINDO/M/M 11.png      \n",
            "  inflating: BISINDO/M/M 12.png      \n",
            "  inflating: BISINDO/M/M 13.png      \n",
            "  inflating: BISINDO/M/M 14.png      \n",
            "  inflating: BISINDO/M/M 15.png      \n",
            "  inflating: BISINDO/M/M 16.png      \n",
            "  inflating: BISINDO/M/M 17.png      \n",
            "  inflating: BISINDO/M/M 18.png      \n",
            "  inflating: BISINDO/M/M 19.png      \n",
            "  inflating: BISINDO/M/M 2.png       \n",
            "  inflating: BISINDO/M/M 20.png      \n",
            "  inflating: BISINDO/M/M 21.png      \n",
            "  inflating: BISINDO/M/M 22.png      \n",
            "  inflating: BISINDO/M/M 23.png      \n",
            "  inflating: BISINDO/M/M 24.png      \n",
            "  inflating: BISINDO/M/M 25.png      \n",
            "  inflating: BISINDO/M/M 26.png      \n",
            "  inflating: BISINDO/M/M 27.png      \n",
            "  inflating: BISINDO/M/M 3.png       \n",
            "  inflating: BISINDO/M/M 7.png       \n",
            "  inflating: BISINDO/M/M 8.png       \n",
            "  inflating: BISINDO/M/M 9.png       \n",
            "  inflating: BISINDO/N/N (1).jpg     \n",
            "  inflating: BISINDO/N/N (10).jpg    \n",
            "  inflating: BISINDO/N/N (11).jpg    \n",
            "  inflating: BISINDO/N/N (12).jpg    \n",
            "  inflating: BISINDO/N/N (2).jpg     \n",
            "  inflating: BISINDO/N/N (3).jpg     \n",
            "  inflating: BISINDO/N/N (4).jpg     \n",
            "  inflating: BISINDO/N/N (5).jpg     \n",
            "  inflating: BISINDO/N/N (6).jpg     \n",
            "  inflating: BISINDO/N/N (7).jpg     \n",
            "  inflating: BISINDO/N/N (8).jpg     \n",
            "  inflating: BISINDO/N/N (9).jpg     \n",
            "  inflating: BISINDO/N/N 1.png       \n",
            "  inflating: BISINDO/N/N 10.png      \n",
            "  inflating: BISINDO/N/N 11.png      \n",
            "  inflating: BISINDO/N/N 12.png      \n",
            "  inflating: BISINDO/N/N 13.png      \n",
            "  inflating: BISINDO/N/N 14.png      \n",
            "  inflating: BISINDO/N/N 15.png      \n",
            "  inflating: BISINDO/N/N 16.png      \n",
            "  inflating: BISINDO/N/N 17.png      \n",
            "  inflating: BISINDO/N/N 18.png      \n",
            "  inflating: BISINDO/N/N 19.png      \n",
            "  inflating: BISINDO/N/N 2.png       \n",
            "  inflating: BISINDO/N/N 20.png      \n",
            "  inflating: BISINDO/N/N 21.png      \n",
            "  inflating: BISINDO/N/N 22.png      \n",
            "  inflating: BISINDO/N/N 23.png      \n",
            "  inflating: BISINDO/N/N 24.png      \n",
            "  inflating: BISINDO/N/N 25.png      \n",
            "  inflating: BISINDO/N/N 26.png      \n",
            "  inflating: BISINDO/N/N 27.png      \n",
            "  inflating: BISINDO/N/N 3.png       \n",
            "  inflating: BISINDO/N/N 7.png       \n",
            "  inflating: BISINDO/N/N 8.png       \n",
            "  inflating: BISINDO/N/N 9.png       \n",
            "  inflating: BISINDO/O/O (1).jpg     \n",
            "  inflating: BISINDO/O/O (10).jpg    \n",
            "  inflating: BISINDO/O/O (11).jpg    \n",
            "  inflating: BISINDO/O/O (12).jpg    \n",
            "  inflating: BISINDO/O/O (2).jpg     \n",
            "  inflating: BISINDO/O/O (3).jpg     \n",
            "  inflating: BISINDO/O/O (4).jpg     \n",
            "  inflating: BISINDO/O/O (5).jpg     \n",
            "  inflating: BISINDO/O/O (6).jpg     \n",
            "  inflating: BISINDO/O/O (7).jpg     \n",
            "  inflating: BISINDO/O/O (8).jpg     \n",
            "  inflating: BISINDO/O/O (9).jpg     \n",
            "  inflating: BISINDO/O/O 1.png       \n",
            "  inflating: BISINDO/O/O 10.png      \n",
            "  inflating: BISINDO/O/O 11.png      \n",
            "  inflating: BISINDO/O/O 12.png      \n",
            "  inflating: BISINDO/O/O 13.png      \n",
            "  inflating: BISINDO/O/O 14.png      \n",
            "  inflating: BISINDO/O/O 15.png      \n",
            "  inflating: BISINDO/O/O 16.png      \n",
            "  inflating: BISINDO/O/O 17.png      \n",
            "  inflating: BISINDO/O/O 18.png      \n",
            "  inflating: BISINDO/O/O 19.png      \n",
            "  inflating: BISINDO/O/O 2.png       \n",
            "  inflating: BISINDO/O/O 20.png      \n",
            "  inflating: BISINDO/O/O 21.png      \n",
            "  inflating: BISINDO/O/O 22.png      \n",
            "  inflating: BISINDO/O/O 23.png      \n",
            "  inflating: BISINDO/O/O 24.png      \n",
            "  inflating: BISINDO/O/O 25.png      \n",
            "  inflating: BISINDO/O/O 26.png      \n",
            "  inflating: BISINDO/O/O 27.png      \n",
            "  inflating: BISINDO/O/O 3.png       \n",
            "  inflating: BISINDO/O/O 7.png       \n",
            "  inflating: BISINDO/O/O 8.png       \n",
            "  inflating: BISINDO/O/O 9.png       \n",
            "  inflating: BISINDO/P/P (1).jpg     \n",
            "  inflating: BISINDO/P/P (10).jpg    \n",
            "  inflating: BISINDO/P/P (11).jpg    \n",
            "  inflating: BISINDO/P/P (12).jpg    \n",
            "  inflating: BISINDO/P/P (13).jpg    \n",
            "  inflating: BISINDO/P/P (14).jpg    \n",
            "  inflating: BISINDO/P/P (2).jpg     \n",
            "  inflating: BISINDO/P/P (3).jpg     \n",
            "  inflating: BISINDO/P/P (6).jpg     \n",
            "  inflating: BISINDO/P/P (7).jpg     \n",
            "  inflating: BISINDO/P/P (8).jpg     \n",
            "  inflating: BISINDO/P/P (9).jpg     \n",
            "  inflating: BISINDO/P/P 1.png       \n",
            "  inflating: BISINDO/P/P 10.png      \n",
            "  inflating: BISINDO/P/P 11.png      \n",
            "  inflating: BISINDO/P/P 12.png      \n",
            "  inflating: BISINDO/P/P 13.png      \n",
            "  inflating: BISINDO/P/P 14.png      \n",
            "  inflating: BISINDO/P/P 15.png      \n",
            "  inflating: BISINDO/P/P 16.png      \n",
            "  inflating: BISINDO/P/P 17.png      \n",
            "  inflating: BISINDO/P/P 18.png      \n",
            "  inflating: BISINDO/P/P 19.png      \n",
            "  inflating: BISINDO/P/P 2.png       \n",
            "  inflating: BISINDO/P/P 20.png      \n",
            "  inflating: BISINDO/P/P 21.png      \n",
            "  inflating: BISINDO/P/P 22.png      \n",
            "  inflating: BISINDO/P/P 23.png      \n",
            "  inflating: BISINDO/P/P 24.png      \n",
            "  inflating: BISINDO/P/P 25.png      \n",
            "  inflating: BISINDO/P/P 26.png      \n",
            "  inflating: BISINDO/P/P 27.png      \n",
            "  inflating: BISINDO/P/P 3.png       \n",
            "  inflating: BISINDO/P/P 7.png       \n",
            "  inflating: BISINDO/P/P 8.png       \n",
            "  inflating: BISINDO/P/P 9.png       \n",
            "  inflating: BISINDO/Q/Q (1).jpg     \n",
            "  inflating: BISINDO/Q/Q (10).jpg    \n",
            "  inflating: BISINDO/Q/Q (11).jpg    \n",
            "  inflating: BISINDO/Q/Q (12).jpg    \n",
            "  inflating: BISINDO/Q/Q (13).jpg    \n",
            "  inflating: BISINDO/Q/Q (14).jpg    \n",
            "  inflating: BISINDO/Q/Q (4).jpg     \n",
            "  inflating: BISINDO/Q/Q (5).jpg     \n",
            "  inflating: BISINDO/Q/Q (6).jpg     \n",
            "  inflating: BISINDO/Q/Q (7).jpg     \n",
            "  inflating: BISINDO/Q/Q (8).jpg     \n",
            "  inflating: BISINDO/Q/Q (9).jpg     \n",
            "  inflating: BISINDO/Q/Q 1.png       \n",
            "  inflating: BISINDO/Q/Q 10.png      \n",
            "  inflating: BISINDO/Q/Q 11.png      \n",
            "  inflating: BISINDO/Q/Q 12.png      \n",
            "  inflating: BISINDO/Q/Q 13.png      \n",
            "  inflating: BISINDO/Q/Q 14.png      \n",
            "  inflating: BISINDO/Q/Q 15.png      \n",
            "  inflating: BISINDO/Q/Q 16.png      \n",
            "  inflating: BISINDO/Q/Q 17.png      \n",
            "  inflating: BISINDO/Q/Q 18.png      \n",
            "  inflating: BISINDO/Q/Q 19.png      \n",
            "  inflating: BISINDO/Q/Q 2.png       \n",
            "  inflating: BISINDO/Q/Q 20.png      \n",
            "  inflating: BISINDO/Q/Q 21.png      \n",
            "  inflating: BISINDO/Q/Q 22.png      \n",
            "  inflating: BISINDO/Q/Q 23.png      \n",
            "  inflating: BISINDO/Q/Q 24.png      \n",
            "  inflating: BISINDO/Q/Q 25.png      \n",
            "  inflating: BISINDO/Q/Q 26.png      \n",
            "  inflating: BISINDO/Q/Q 27.png      \n",
            "  inflating: BISINDO/Q/Q 3.png       \n",
            "  inflating: BISINDO/Q/Q 7.png       \n",
            "  inflating: BISINDO/Q/Q 8.png       \n",
            "  inflating: BISINDO/Q/Q 9.png       \n",
            "  inflating: BISINDO/R/R (1).jpg     \n",
            "  inflating: BISINDO/R/R (10).jpg    \n",
            "  inflating: BISINDO/R/R (11).jpg    \n",
            "  inflating: BISINDO/R/R (12).jpg    \n",
            "  inflating: BISINDO/R/R (13).jpg    \n",
            "  inflating: BISINDO/R/R (14).jpg    \n",
            "  inflating: BISINDO/R/R (4).jpg     \n",
            "  inflating: BISINDO/R/R (5).jpg     \n",
            "  inflating: BISINDO/R/R (6).jpg     \n",
            "  inflating: BISINDO/R/R (7).jpg     \n",
            "  inflating: BISINDO/R/R (8).jpg     \n",
            "  inflating: BISINDO/R/R (9).jpg     \n",
            "  inflating: BISINDO/R/R 1.png       \n",
            "  inflating: BISINDO/R/R 10.png      \n",
            "  inflating: BISINDO/R/R 11.png      \n",
            "  inflating: BISINDO/R/R 12.png      \n",
            "  inflating: BISINDO/R/R 13.png      \n",
            "  inflating: BISINDO/R/R 14.png      \n",
            "  inflating: BISINDO/R/R 15.png      \n",
            "  inflating: BISINDO/R/R 16.png      \n",
            "  inflating: BISINDO/R/R 17.png      \n",
            "  inflating: BISINDO/R/R 18.png      \n",
            "  inflating: BISINDO/R/R 19.png      \n",
            "  inflating: BISINDO/R/R 2.png       \n",
            "  inflating: BISINDO/R/R 20.png      \n",
            "  inflating: BISINDO/R/R 21.png      \n",
            "  inflating: BISINDO/R/R 22.png      \n",
            "  inflating: BISINDO/R/R 23.png      \n",
            "  inflating: BISINDO/R/R 24.png      \n",
            "  inflating: BISINDO/R/R 25.png      \n",
            "  inflating: BISINDO/R/R 26.png      \n",
            "  inflating: BISINDO/R/R 27.png      \n",
            "  inflating: BISINDO/R/R 3.png       \n",
            "  inflating: BISINDO/R/R 7.png       \n",
            "  inflating: BISINDO/R/R 8.png       \n",
            "  inflating: BISINDO/R/R 9.png       \n",
            "  inflating: BISINDO/S/S (1).jpg     \n",
            "  inflating: BISINDO/S/S (10).jpg    \n",
            "  inflating: BISINDO/S/S (11).jpg    \n",
            "  inflating: BISINDO/S/S (12).jpg    \n",
            "  inflating: BISINDO/S/S (13).jpg    \n",
            "  inflating: BISINDO/S/S (14).jpg    \n",
            "  inflating: BISINDO/S/S (4).jpg     \n",
            "  inflating: BISINDO/S/S (5).jpg     \n",
            "  inflating: BISINDO/S/S (6).jpg     \n",
            "  inflating: BISINDO/S/S (7).jpg     \n",
            "  inflating: BISINDO/S/S (8).jpg     \n",
            "  inflating: BISINDO/S/S (9).jpg     \n",
            "  inflating: BISINDO/S/S 1.png       \n",
            "  inflating: BISINDO/S/S 10.png      \n",
            "  inflating: BISINDO/S/S 11.png      \n",
            "  inflating: BISINDO/S/S 12.png      \n",
            "  inflating: BISINDO/S/S 13.png      \n",
            "  inflating: BISINDO/S/S 14.png      \n",
            "  inflating: BISINDO/S/S 15.png      \n",
            "  inflating: BISINDO/S/S 16.png      \n",
            "  inflating: BISINDO/S/S 17.png      \n",
            "  inflating: BISINDO/S/S 18.png      \n",
            "  inflating: BISINDO/S/S 19.png      \n",
            "  inflating: BISINDO/S/S 2.png       \n",
            "  inflating: BISINDO/S/S 20.png      \n",
            "  inflating: BISINDO/S/S 21.png      \n",
            "  inflating: BISINDO/S/S 22.png      \n",
            "  inflating: BISINDO/S/S 23.png      \n",
            "  inflating: BISINDO/S/S 24.png      \n",
            "  inflating: BISINDO/S/S 25.png      \n",
            "  inflating: BISINDO/S/S 26.png      \n",
            "  inflating: BISINDO/S/S 27.png      \n",
            "  inflating: BISINDO/S/S 3.png       \n",
            "  inflating: BISINDO/S/S 7.png       \n",
            "  inflating: BISINDO/S/S 8.png       \n",
            "  inflating: BISINDO/S/S 9.png       \n",
            "  inflating: BISINDO/T/T  17.png     \n",
            "  inflating: BISINDO/T/T  19.png     \n",
            "  inflating: BISINDO/T/T (1).jpg     \n",
            "  inflating: BISINDO/T/T (10).jpg    \n",
            "  inflating: BISINDO/T/T (11).jpg    \n",
            "  inflating: BISINDO/T/T (12).jpg    \n",
            "  inflating: BISINDO/T/T (13).jpg    \n",
            "  inflating: BISINDO/T/T (14).jpg    \n",
            "  inflating: BISINDO/T/T (4).jpg     \n",
            "  inflating: BISINDO/T/T (5).jpg     \n",
            "  inflating: BISINDO/T/T (6).jpg     \n",
            "  inflating: BISINDO/T/T (7).jpg     \n",
            "  inflating: BISINDO/T/T (8).jpg     \n",
            "  inflating: BISINDO/T/T (9).jpg     \n",
            "  inflating: BISINDO/T/T 1.png       \n",
            "  inflating: BISINDO/T/T 10.png      \n",
            "  inflating: BISINDO/T/T 11.png      \n",
            "  inflating: BISINDO/T/T 12.png      \n",
            "  inflating: BISINDO/T/T 13.png      \n",
            "  inflating: BISINDO/T/T 14.png      \n",
            "  inflating: BISINDO/T/T 15.png      \n",
            "  inflating: BISINDO/T/T 16.png      \n",
            "  inflating: BISINDO/T/T 18.png      \n",
            "  inflating: BISINDO/T/T 2.png       \n",
            "  inflating: BISINDO/T/T 20.png      \n",
            "  inflating: BISINDO/T/T 21.png      \n",
            "  inflating: BISINDO/T/T 22.png      \n",
            "  inflating: BISINDO/T/T 23.png      \n",
            "  inflating: BISINDO/T/T 24.png      \n",
            "  inflating: BISINDO/T/T 25.png      \n",
            "  inflating: BISINDO/T/T 26.png      \n",
            "  inflating: BISINDO/T/T 27.png      \n",
            "  inflating: BISINDO/T/T 3.png       \n",
            "  inflating: BISINDO/T/T 7.png       \n",
            "  inflating: BISINDO/T/T 8.png       \n",
            "  inflating: BISINDO/T/T 9.png       \n",
            "  inflating: BISINDO/U/U (1).jpg     \n",
            "  inflating: BISINDO/U/U (10).jpg    \n",
            "  inflating: BISINDO/U/U (11).jpg    \n",
            "  inflating: BISINDO/U/U (12).jpg    \n",
            "  inflating: BISINDO/U/U (13).jpg    \n",
            "  inflating: BISINDO/U/U (14).jpg    \n",
            "  inflating: BISINDO/U/U (4).jpg     \n",
            "  inflating: BISINDO/U/U (5).jpg     \n",
            "  inflating: BISINDO/U/U (6).jpg     \n",
            "  inflating: BISINDO/U/U (7).jpg     \n",
            "  inflating: BISINDO/U/U (8).jpg     \n",
            "  inflating: BISINDO/U/U (9).jpg     \n",
            "  inflating: BISINDO/U/U 1.png       \n",
            "  inflating: BISINDO/U/U 10.png      \n",
            "  inflating: BISINDO/U/U 11.png      \n",
            "  inflating: BISINDO/U/U 12.png      \n",
            "  inflating: BISINDO/U/U 13.png      \n",
            "  inflating: BISINDO/U/U 14.png      \n",
            "  inflating: BISINDO/U/U 15.png      \n",
            "  inflating: BISINDO/U/U 16.png      \n",
            "  inflating: BISINDO/U/U 17.png      \n",
            "  inflating: BISINDO/U/U 18.png      \n",
            "  inflating: BISINDO/U/U 19.png      \n",
            "  inflating: BISINDO/U/U 2.png       \n",
            "  inflating: BISINDO/U/U 20.png      \n",
            "  inflating: BISINDO/U/U 21.png      \n",
            "  inflating: BISINDO/U/U 22.png      \n",
            "  inflating: BISINDO/U/U 23.png      \n",
            "  inflating: BISINDO/U/U 24.png      \n",
            "  inflating: BISINDO/U/U 25.png      \n",
            "  inflating: BISINDO/U/U 26.png      \n",
            "  inflating: BISINDO/U/U 27.png      \n",
            "  inflating: BISINDO/U/U 3.png       \n",
            "  inflating: BISINDO/U/U 7.png       \n",
            "  inflating: BISINDO/U/U 8.png       \n",
            "  inflating: BISINDO/U/U 9.png       \n",
            "  inflating: BISINDO/V/V (1).jpg     \n",
            "  inflating: BISINDO/V/V (10).jpg    \n",
            "  inflating: BISINDO/V/V (11).jpg    \n",
            "  inflating: BISINDO/V/V (12).jpg    \n",
            "  inflating: BISINDO/V/V (13).jpg    \n",
            "  inflating: BISINDO/V/V (14).jpg    \n",
            "  inflating: BISINDO/V/V (4).jpg     \n",
            "  inflating: BISINDO/V/V (5).jpg     \n",
            "  inflating: BISINDO/V/V (6).jpg     \n",
            "  inflating: BISINDO/V/V (7).jpg     \n",
            "  inflating: BISINDO/V/V (8).jpg     \n",
            "  inflating: BISINDO/V/V (9).jpg     \n",
            "  inflating: BISINDO/V/V 1.png       \n",
            "  inflating: BISINDO/V/V 10.png      \n",
            "  inflating: BISINDO/V/V 11.png      \n",
            "  inflating: BISINDO/V/V 12.png      \n",
            "  inflating: BISINDO/V/V 13.png      \n",
            "  inflating: BISINDO/V/V 14.png      \n",
            "  inflating: BISINDO/V/V 15.png      \n",
            "  inflating: BISINDO/V/V 17.png      \n",
            "  inflating: BISINDO/V/V 18.png      \n",
            "  inflating: BISINDO/V/V 19.png      \n",
            "  inflating: BISINDO/V/V 2.png       \n",
            "  inflating: BISINDO/V/V 20.png      \n",
            "  inflating: BISINDO/V/V 21.png      \n",
            "  inflating: BISINDO/V/V 22.png      \n",
            "  inflating: BISINDO/V/V 23.png      \n",
            "  inflating: BISINDO/V/V 24.png      \n",
            "  inflating: BISINDO/V/V 25.png      \n",
            "  inflating: BISINDO/V/V 26.png      \n",
            "  inflating: BISINDO/V/V 27.png      \n",
            "  inflating: BISINDO/V/V 3.png       \n",
            "  inflating: BISINDO/V/V 7.png       \n",
            "  inflating: BISINDO/V/V 8.png       \n",
            "  inflating: BISINDO/V/V 9.png       \n",
            "  inflating: BISINDO/V/v 16.png      \n",
            "  inflating: BISINDO/W/W (1).jpg     \n",
            "  inflating: BISINDO/W/W (10).jpg    \n",
            "  inflating: BISINDO/W/W (11).jpg    \n",
            "  inflating: BISINDO/W/W (12).jpg    \n",
            "  inflating: BISINDO/W/W (13).jpg    \n",
            "  inflating: BISINDO/W/W (14).jpg    \n",
            "  inflating: BISINDO/W/W (4).jpg     \n",
            "  inflating: BISINDO/W/W (5).jpg     \n",
            "  inflating: BISINDO/W/W (6).jpg     \n",
            "  inflating: BISINDO/W/W (7).jpg     \n",
            "  inflating: BISINDO/W/W (8).jpg     \n",
            "  inflating: BISINDO/W/W (9).jpg     \n",
            "  inflating: BISINDO/W/W 1.png       \n",
            "  inflating: BISINDO/W/W 10.png      \n",
            "  inflating: BISINDO/W/W 11.png      \n",
            "  inflating: BISINDO/W/W 12.png      \n",
            "  inflating: BISINDO/W/W 13.png      \n",
            "  inflating: BISINDO/W/W 14.png      \n",
            "  inflating: BISINDO/W/W 15.png      \n",
            "  inflating: BISINDO/W/W 16.png      \n",
            "  inflating: BISINDO/W/W 17.png      \n",
            "  inflating: BISINDO/W/W 18.png      \n",
            "  inflating: BISINDO/W/W 19.png      \n",
            "  inflating: BISINDO/W/W 2.png       \n",
            "  inflating: BISINDO/W/W 20.png      \n",
            "  inflating: BISINDO/W/W 21.png      \n",
            "  inflating: BISINDO/W/W 22.png      \n",
            "  inflating: BISINDO/W/W 23.png      \n",
            "  inflating: BISINDO/W/W 24.png      \n",
            "  inflating: BISINDO/W/W 25.png      \n",
            "  inflating: BISINDO/W/W 26.png      \n",
            "  inflating: BISINDO/W/W 27.png      \n",
            "  inflating: BISINDO/W/W 3.png       \n",
            "  inflating: BISINDO/W/W 7.png       \n",
            "  inflating: BISINDO/W/W 8.png       \n",
            "  inflating: BISINDO/W/W 9.png       \n",
            "  inflating: BISINDO/X/X (1).jpg     \n",
            "  inflating: BISINDO/X/X (10).jpg    \n",
            "  inflating: BISINDO/X/X (11).jpg    \n",
            "  inflating: BISINDO/X/X (12).jpg    \n",
            "  inflating: BISINDO/X/X (13).jpg    \n",
            "  inflating: BISINDO/X/X (14).jpg    \n",
            "  inflating: BISINDO/X/X (4).jpg     \n",
            "  inflating: BISINDO/X/X (5).jpg     \n",
            "  inflating: BISINDO/X/X (6).jpg     \n",
            "  inflating: BISINDO/X/X (7).jpg     \n",
            "  inflating: BISINDO/X/X (8).jpg     \n",
            "  inflating: BISINDO/X/X (9).jpg     \n",
            "  inflating: BISINDO/X/X 1.png       \n",
            "  inflating: BISINDO/X/X 10.png      \n",
            "  inflating: BISINDO/X/X 11.png      \n",
            "  inflating: BISINDO/X/X 12.png      \n",
            "  inflating: BISINDO/X/X 13.png      \n",
            "  inflating: BISINDO/X/X 14.png      \n",
            "  inflating: BISINDO/X/X 15.png      \n",
            "  inflating: BISINDO/X/X 16.png      \n",
            "  inflating: BISINDO/X/X 17.png      \n",
            "  inflating: BISINDO/X/X 18.png      \n",
            "  inflating: BISINDO/X/X 19.png      \n",
            "  inflating: BISINDO/X/X 2.png       \n",
            "  inflating: BISINDO/X/X 20.png      \n",
            "  inflating: BISINDO/X/X 21.png      \n",
            "  inflating: BISINDO/X/X 22.png      \n",
            "  inflating: BISINDO/X/X 23.png      \n",
            "  inflating: BISINDO/X/X 24.png      \n",
            "  inflating: BISINDO/X/X 25.png      \n",
            "  inflating: BISINDO/X/X 26.png      \n",
            "  inflating: BISINDO/X/X 27.png      \n",
            "  inflating: BISINDO/X/X 3.png       \n",
            "  inflating: BISINDO/X/X 7.png       \n",
            "  inflating: BISINDO/X/X 8.png       \n",
            "  inflating: BISINDO/X/X 9.png       \n",
            "  inflating: BISINDO/Y/Y (1).jpg     \n",
            "  inflating: BISINDO/Y/Y (10).jpg    \n",
            "  inflating: BISINDO/Y/Y (11).jpg    \n",
            "  inflating: BISINDO/Y/Y (12).jpg    \n",
            "  inflating: BISINDO/Y/Y (13).jpg    \n",
            "  inflating: BISINDO/Y/Y (14).jpg    \n",
            "  inflating: BISINDO/Y/Y (4).jpg     \n",
            "  inflating: BISINDO/Y/Y (5).jpg     \n",
            "  inflating: BISINDO/Y/Y (6).jpg     \n",
            "  inflating: BISINDO/Y/Y (7).jpg     \n",
            "  inflating: BISINDO/Y/Y (8).jpg     \n",
            "  inflating: BISINDO/Y/Y (9).jpg     \n",
            "  inflating: BISINDO/Y/Y 1.png       \n",
            "  inflating: BISINDO/Y/Y 10.png      \n",
            "  inflating: BISINDO/Y/Y 11.png      \n",
            "  inflating: BISINDO/Y/Y 12.png      \n",
            "  inflating: BISINDO/Y/Y 13.png      \n",
            "  inflating: BISINDO/Y/Y 14.png      \n",
            "  inflating: BISINDO/Y/Y 15.png      \n",
            "  inflating: BISINDO/Y/Y 16.png      \n",
            "  inflating: BISINDO/Y/Y 17.png      \n",
            "  inflating: BISINDO/Y/Y 18.png      \n",
            "  inflating: BISINDO/Y/Y 19.png      \n",
            "  inflating: BISINDO/Y/Y 2.png       \n",
            "  inflating: BISINDO/Y/Y 20.png      \n",
            "  inflating: BISINDO/Y/Y 21.png      \n",
            "  inflating: BISINDO/Y/Y 22.png      \n",
            "  inflating: BISINDO/Y/Y 23.png      \n",
            "  inflating: BISINDO/Y/Y 24.png      \n",
            "  inflating: BISINDO/Y/Y 25.png      \n",
            "  inflating: BISINDO/Y/Y 26.png      \n",
            "  inflating: BISINDO/Y/Y 27.png      \n",
            "  inflating: BISINDO/Y/Y 3.png       \n",
            "  inflating: BISINDO/Y/Y 7.png       \n",
            "  inflating: BISINDO/Y/Y 8.png       \n",
            "  inflating: BISINDO/Y/Y 9.png       \n",
            "  inflating: BISINDO/Z/Z (1).jpg     \n",
            "  inflating: BISINDO/Z/Z (10).jpg    \n",
            "  inflating: BISINDO/Z/Z (11).jpg    \n",
            "  inflating: BISINDO/Z/Z (12).jpg    \n",
            "  inflating: BISINDO/Z/Z (13).jpg    \n",
            "  inflating: BISINDO/Z/Z (14).jpg    \n",
            "  inflating: BISINDO/Z/Z (15).jpg    \n",
            "  inflating: BISINDO/Z/Z (16).jpg    \n",
            "  inflating: BISINDO/Z/Z (2).jpg     \n",
            "  inflating: BISINDO/Z/Z (3).jpg     \n",
            "  inflating: BISINDO/Z/Z (8).jpg     \n",
            "  inflating: BISINDO/Z/Z (9).jpg     \n",
            "  inflating: BISINDO/Z/Z 1.png       \n",
            "  inflating: BISINDO/Z/Z 10.png      \n",
            "  inflating: BISINDO/Z/Z 11.png      \n",
            "  inflating: BISINDO/Z/Z 12.png      \n",
            "  inflating: BISINDO/Z/Z 13.png      \n",
            "  inflating: BISINDO/Z/Z 14.png      \n",
            "  inflating: BISINDO/Z/Z 15.png      \n",
            "  inflating: BISINDO/Z/Z 16.png      \n",
            "  inflating: BISINDO/Z/Z 17.png      \n",
            "  inflating: BISINDO/Z/Z 18.png      \n",
            "  inflating: BISINDO/Z/Z 19.png      \n",
            "  inflating: BISINDO/Z/Z 2.png       \n",
            "  inflating: BISINDO/Z/Z 20.png      \n",
            "  inflating: BISINDO/Z/Z 21.png      \n",
            "  inflating: BISINDO/Z/Z 22.png      \n",
            "  inflating: BISINDO/Z/Z 23.png      \n",
            "  inflating: BISINDO/Z/Z 24.png      \n",
            "  inflating: BISINDO/Z/Z 25.png      \n",
            "  inflating: BISINDO/Z/Z 26.png      \n",
            "  inflating: BISINDO/Z/Z 27.png      \n",
            "  inflating: BISINDO/Z/Z 3.png       \n",
            "  inflating: BISINDO/Z/Z 7.png       \n",
            "  inflating: BISINDO/Z/Z 8.png       \n",
            "  inflating: BISINDO/Z/Z 9.png       \n"
          ]
        }
      ],
      "source": [
        "!unzip bisindo-letter-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_folder = \"path/to/unzipped/dataset/folder\"\n",
        "\n",
        "# Iterate over each letter (A to Z)\n",
        "for letter in range(ord('A'), ord('Z') + 1):\n",
        "    letter_folder = chr(letter)\n",
        "    letter_folder_path = os.path.join(dataset_folder, letter_folder)\n",
        "\n",
        "    # Check if the letter folder exists\n",
        "    if os.path.isdir(letter_folder_path):\n",
        "        # Count the number of images in the letter folder\n",
        "        image_count = len(os.listdir(letter_folder_path))\n",
        "\n",
        "        print(f\"Total images in category {letter_folder}: {image_count}\")\n",
        "    else:\n",
        "        print(f\"Category {letter_folder} does not exist.\")\n"
      ],
      "metadata": {
        "id": "XaPf0RqH0Pm0",
        "outputId": "eca503b3-e963-4cd5-eaa2-1a820f5c9b2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category A does not exist.\n",
            "Category B does not exist.\n",
            "Category C does not exist.\n",
            "Category D does not exist.\n",
            "Category E does not exist.\n",
            "Category F does not exist.\n",
            "Category G does not exist.\n",
            "Category H does not exist.\n",
            "Category I does not exist.\n",
            "Category J does not exist.\n",
            "Category K does not exist.\n",
            "Category L does not exist.\n",
            "Category M does not exist.\n",
            "Category N does not exist.\n",
            "Category O does not exist.\n",
            "Category P does not exist.\n",
            "Category Q does not exist.\n",
            "Category R does not exist.\n",
            "Category S does not exist.\n",
            "Category T does not exist.\n",
            "Category U does not exist.\n",
            "Category V does not exist.\n",
            "Category W does not exist.\n",
            "Category X does not exist.\n",
            "Category Y does not exist.\n",
            "Category Z does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrtEhmLwgsEk",
        "outputId": "070c1e7b-e49b-4e4f-bbf0-7afdd3984f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 91.81%\n",
            "Precision: 92.58%\n",
            "Recall: 91.81%\n",
            "F1 score: 91.76%\n"
          ]
        }
      ],
      "source": [
        "#SVM MODEL 1\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import os\n",
        "\n",
        "# Extract features using HOG\n",
        "def extract_features(img):\n",
        "    winSize = (64, 64)\n",
        "    blockSize = (16, 16)\n",
        "    blockStride = (8, 8)\n",
        "    cellSize = (8, 8)\n",
        "    nbins = 9\n",
        "    hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\n",
        "    return hog.compute(img).reshape(1, -1)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for label, letter in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
        "    letter_dir = os.path.join('/content/BISINDO', letter)\n",
        "    for filename in os.listdir(letter_dir):\n",
        "        file_path = os.path.join(letter_dir, filename)\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        roi = cv2.resize(img, (64, 64))\n",
        "        features = extract_features(roi)\n",
        "        X.append(features)\n",
        "        y.append(label)\n",
        "\n",
        "# Convert the feature and label lists to numpy arrays\n",
        "X = np.concatenate(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train an SVM model on the training data\n",
        "model = svm.SVC(kernel='linear', C=1, gamma='scale')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "print('Precision: {:.2f}%'.format(precision * 100))\n",
        "print('Recall: {:.2f}%'.format(recall * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1 * 100))\n",
        "\n",
        "# Deploy the model for sign language recognition\n",
        "cap = cv2.VideoCapture(0)\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame = cv2.flip(frame, 1)\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    roi = cv2.resize(gray, (64, 64))\n",
        "    features = extract_features(roi)\n",
        "    sign = model.predict(features)\n",
        "    cv2.putText(frame, chr(sign[0] + ord('A')), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "    cv2.imshow('Sign Language Recognition', frame)\n",
        "    if cv2.waitKey(1) == ord('z'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM MODEL 2\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import os\n",
        "\n",
        "# Extract features using HOG\n",
        "def extract_features(img):\n",
        "    winSize = (64, 64)\n",
        "    blockSize = (16, 16)\n",
        "    blockStride = (8, 8)\n",
        "    cellSize = (8, 8)\n",
        "    nbins = 9\n",
        "    hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\n",
        "    return hog.compute(img).reshape(1, -1)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for label, letter in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
        "    letter_dir = os.path.join('/content/BISINDO', letter)\n",
        "    for filename in os.listdir(letter_dir):\n",
        "        file_path = os.path.join(letter_dir, filename)\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        roi = cv2.resize(img, (64, 64))\n",
        "        features = extract_features(roi)\n",
        "        X.append(features)\n",
        "        y.append(label)\n",
        "\n",
        "# Convert the feature and label lists to numpy arrays\n",
        "X = np.concatenate(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train an SVM model on the training data\n",
        "model = svm.SVC(kernel='rbf', C=10, gamma=0.001)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "print('Precision: {:.2f}%'.format(precision * 100))\n",
        "print('Recall: {:.2f}%'.format(recall * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1 * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3QZ_ZAuHO04",
        "outputId": "178f270e-76bc-49e0-820f-7a3ea12c01fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 80.43%\n",
            "Precision: 85.91%\n",
            "Recall: 80.43%\n",
            "F1 score: 80.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3huBy0xNut1x",
        "outputId": "0e74f334-fe9f-419a-e416-47d6b0a3532b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 9s 217ms/step - loss: 3.2091 - accuracy: 0.0789\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 6s 252ms/step - loss: 2.3858 - accuracy: 0.3409\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 5s 195ms/step - loss: 1.3113 - accuracy: 0.6457\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 5s 197ms/step - loss: 0.7002 - accuracy: 0.7928\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 6s 253ms/step - loss: 0.3421 - accuracy: 0.8904\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 5s 197ms/step - loss: 0.1639 - accuracy: 0.9559\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 6s 254ms/step - loss: 0.0702 - accuracy: 0.9786\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 5s 198ms/step - loss: 0.0402 - accuracy: 0.9893\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 5s 195ms/step - loss: 0.0254 - accuracy: 0.9947\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 6s 257ms/step - loss: 0.0127 - accuracy: 0.9973\n",
            "6/6 [==============================] - 0s 50ms/step\n",
            "Accuracy: 77.13%\n",
            "Precision: 83.55%\n",
            "Recall: 77.13%\n",
            "F1 score: 77.67%\n"
          ]
        }
      ],
      "source": [
        "#CNN MODEL 1 (TEST SIZE 0.2, LAYERING -> 128)\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the CNN model\n",
        "def get_model(input_shape):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(26, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for label, letter in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
        "    letter_dir = os.path.join('/content/BISINDO', letter)\n",
        "    for filename in os.listdir(letter_dir):\n",
        "        file_path = os.path.join(letter_dir, filename)\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        roi = cv2.resize(img, (64, 64))\n",
        "        X.append(roi)\n",
        "        y.append(label)\n",
        "\n",
        "# Convert the feature and label lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n",
        "\n",
        "# Reshape the training and testing sets to have 4 dimensions\n",
        "X_train = X_train.reshape(-1, 64, 64, 1)\n",
        "X_test = X_test.reshape(-1, 64, 64, 1)\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Create and train the CNN model\n",
        "model = get_model(X_train[0].shape)\n",
        "model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "print('Precision: {:.2f}%'.format(precision * 100))\n",
        "print('Recall: {:.2f}%'.format(recall * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1 * 100))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN MODEL 1 TEST SIZE 0.3 Using 256 filters\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "def get_model(input_shape):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dense(26, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for label, letter in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
        "    letter_dir = os.path.join('/content/BISINDO', letter)\n",
        "    for filename in os.listdir(letter_dir):\n",
        "        file_path = os.path.join(letter_dir, filename)\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        roi = cv2.resize(img, (64, 64))\n",
        "        X.append(roi)\n",
        "        y.append(label)\n",
        "\n",
        "# Convert the feature and label lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Reshape the training and testing sets to have 4 dimensions\n",
        "X_train = X_train.reshape(-1, 64, 64, 1)\n",
        "X_test = X_test.reshape(-1, 64, 64, 1)\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Create and train the CNN model\n",
        "model = get_model(X_train[0].shape)\n",
        "model.fit(X_train, y_train, epochs=15)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "print('Precision: {:.2f}%'.format(precision * 100))\n",
        "print('Recall: {:.2f}%'.format(recall * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1 * 100))\n",
        "\n"
      ],
      "metadata": {
        "id": "Kj4y4jZlFSS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c0ea2ca-1094-448c-a677-54ea2d1aab46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "21/21 [==============================] - 9s 357ms/step - loss: 3.2117 - accuracy: 0.1176\n",
            "Epoch 2/15\n",
            "21/21 [==============================] - 6s 291ms/step - loss: 2.0064 - accuracy: 0.4672\n",
            "Epoch 3/15\n",
            "21/21 [==============================] - 7s 358ms/step - loss: 1.0066 - accuracy: 0.7099\n",
            "Epoch 4/15\n",
            "21/21 [==============================] - 6s 290ms/step - loss: 0.4374 - accuracy: 0.8687\n",
            "Epoch 5/15\n",
            "21/21 [==============================] - 8s 361ms/step - loss: 0.2144 - accuracy: 0.9435\n",
            "Epoch 6/15\n",
            "21/21 [==============================] - 6s 289ms/step - loss: 0.1184 - accuracy: 0.9664\n",
            "Epoch 7/15\n",
            "21/21 [==============================] - 8s 361ms/step - loss: 0.0633 - accuracy: 0.9847\n",
            "Epoch 8/15\n",
            "21/21 [==============================] - 6s 289ms/step - loss: 0.0200 - accuracy: 0.9954\n",
            "Epoch 9/15\n",
            "21/21 [==============================] - 7s 360ms/step - loss: 0.0362 - accuracy: 0.9924\n",
            "Epoch 10/15\n",
            "21/21 [==============================] - 6s 290ms/step - loss: 0.0107 - accuracy: 0.9985\n",
            "Epoch 11/15\n",
            "21/21 [==============================] - 8s 363ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "21/21 [==============================] - 6s 290ms/step - loss: 9.2937e-04 - accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "21/21 [==============================] - 8s 363ms/step - loss: 5.2357e-04 - accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "21/21 [==============================] - 6s 288ms/step - loss: 3.7394e-04 - accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "21/21 [==============================] - 10s 493ms/step - loss: 3.0532e-04 - accuracy: 1.0000\n",
            "9/9 [==============================] - 1s 72ms/step\n",
            "Accuracy: 81.14%\n",
            "Precision: 81.86%\n",
            "Recall: 81.14%\n",
            "F1 score: 80.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHvZGoWI6T2w",
        "outputId": "b90991da-a3bd-4b78-f27b-6f28ac730d3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "21/21 [==============================] - 8s 293ms/step - loss: 3.2473 - accuracy: 0.1023\n",
            "Epoch 2/15\n",
            "21/21 [==============================] - 5s 215ms/step - loss: 2.7211 - accuracy: 0.2779\n",
            "Epoch 3/15\n",
            "21/21 [==============================] - 7s 328ms/step - loss: 1.5528 - accuracy: 0.5618\n",
            "Epoch 4/15\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.8146 - accuracy: 0.7542\n",
            "Epoch 5/15\n",
            "21/21 [==============================] - 6s 273ms/step - loss: 0.4406 - accuracy: 0.8595\n",
            "Epoch 6/15\n",
            "21/21 [==============================] - 7s 330ms/step - loss: 0.1581 - accuracy: 0.9588\n",
            "Epoch 7/15\n",
            "21/21 [==============================] - 8s 373ms/step - loss: 0.0871 - accuracy: 0.9725\n",
            "Epoch 8/15\n",
            "21/21 [==============================] - 6s 263ms/step - loss: 0.0401 - accuracy: 0.9924\n",
            "Epoch 9/15\n",
            "21/21 [==============================] - 7s 331ms/step - loss: 0.0256 - accuracy: 0.9939\n",
            "Epoch 10/15\n",
            "21/21 [==============================] - 9s 429ms/step - loss: 0.0171 - accuracy: 0.9954\n",
            "Epoch 11/15\n",
            "21/21 [==============================] - 5s 233ms/step - loss: 0.0037 - accuracy: 0.9985\n",
            "Epoch 12/15\n",
            "21/21 [==============================] - 6s 267ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "21/21 [==============================] - 7s 319ms/step - loss: 7.2883e-04 - accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "21/21 [==============================] - 7s 333ms/step - loss: 5.6003e-04 - accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "21/21 [==============================] - 6s 260ms/step - loss: 4.5922e-04 - accuracy: 1.0000\n",
            "9/9 [==============================] - 1s 108ms/step\n",
            "Accuracy: 82.56%\n",
            "Precision: 84.76%\n",
            "Recall: 82.56%\n",
            "F1 score: 82.30%\n"
          ]
        }
      ],
      "source": [
        "#CNN MODEL 1 TEST SIZE 0.3 Using 128 filters\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# CNN model\n",
        "def get_model(input_shape):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(26, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for label, letter in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
        "    letter_dir = os.path.join('/content/BISINDO', letter)\n",
        "    for filename in os.listdir(letter_dir):\n",
        "        file_path = os.path.join(letter_dir, filename)\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        roi = cv2.resize(img, (64, 64))\n",
        "        X.append(roi)\n",
        "        y.append(label)\n",
        "\n",
        "# Convert the feature and label lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Reshape the training and testing sets to have 4 dimensions\n",
        "X_train = X_train.reshape(-1, 64, 64, 1)\n",
        "X_test = X_test.reshape(-1, 64, 64, 1)\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Create and train the CNN model\n",
        "model = get_model(X_train[0].shape)\n",
        "model.fit(X_train, y_train, epochs=15)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "print('Precision: {:.2f}%'.format(precision * 100))\n",
        "print('Recall: {:.2f}%'.format(recall * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1 * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN MODEL 3 USING 64 FILTER\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# CNN model\n",
        "def get_model(input_shape):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),  # Updated: Changed to 64 units\n",
        "        tf.keras.layers.Dense(26, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for label, letter in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
        "    letter_dir = os.path.join('/content/BISINDO', letter)\n",
        "    for filename in os.listdir(letter_dir):\n",
        "        file_path = os.path.join(letter_dir, filename)\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        roi = cv2.resize(img, (64, 64))\n",
        "        X.append(roi)\n",
        "        y.append(label)\n",
        "\n",
        "# Convert the feature and label lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Reshape the training and testing sets to have 4 dimensions\n",
        "X_train = X_train.reshape(-1, 64, 64, 1)\n",
        "X_test = X_test.reshape(-1, 64, 64, 1)\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Create and train the CNN model\n",
        "model = get_model(X_train[0].shape)\n",
        "model.fit(X_train, y_train, epochs=15)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "print('Precision: {:.2f}%'.format(precision * 100))\n",
        "print('Recall: {:.2f}%'.format(recall * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1 * 100))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiqQKM0MWQgZ",
        "outputId": "a954a6a5-570a-4b0a-a9d3-04684bcd7548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "21/21 [==============================] - 6s 240ms/step - loss: 3.2590 - accuracy: 0.0473\n",
            "Epoch 2/15\n",
            "21/21 [==============================] - 5s 255ms/step - loss: 3.2392 - accuracy: 0.0458\n",
            "Epoch 3/15\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 3.0093 - accuracy: 0.1649\n",
            "Epoch 4/15\n",
            "21/21 [==============================] - 6s 284ms/step - loss: 2.3130 - accuracy: 0.3557\n",
            "Epoch 5/15\n",
            "21/21 [==============================] - 4s 211ms/step - loss: 1.6163 - accuracy: 0.5176\n",
            "Epoch 6/15\n",
            "21/21 [==============================] - 4s 211ms/step - loss: 1.2217 - accuracy: 0.6336\n",
            "Epoch 7/15\n",
            "21/21 [==============================] - 6s 289ms/step - loss: 0.8545 - accuracy: 0.7542\n",
            "Epoch 8/15\n",
            "21/21 [==============================] - 10s 473ms/step - loss: 0.5626 - accuracy: 0.8351\n",
            "Epoch 9/15\n",
            "21/21 [==============================] - 7s 332ms/step - loss: 0.3923 - accuracy: 0.8763\n",
            "Epoch 10/15\n",
            "21/21 [==============================] - 7s 358ms/step - loss: 0.2637 - accuracy: 0.9206\n",
            "Epoch 11/15\n",
            "21/21 [==============================] - 7s 328ms/step - loss: 0.1508 - accuracy: 0.9573\n",
            "Epoch 12/15\n",
            "21/21 [==============================] - 9s 425ms/step - loss: 0.1364 - accuracy: 0.9649\n",
            "Epoch 13/15\n",
            "21/21 [==============================] - 5s 228ms/step - loss: 0.0871 - accuracy: 0.9786\n",
            "Epoch 14/15\n",
            "21/21 [==============================] - 8s 380ms/step - loss: 0.0758 - accuracy: 0.9786\n",
            "Epoch 15/15\n",
            "21/21 [==============================] - 5s 225ms/step - loss: 0.0727 - accuracy: 0.9817\n",
            "9/9 [==============================] - 1s 55ms/step\n",
            "Accuracy: 80.78%\n",
            "Precision: 83.61%\n",
            "Recall: 80.78%\n",
            "F1 score: 80.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# THE CODE BELOW IS THE EXPERIMENT CODE OF EPOCH"
      ],
      "metadata": {
        "id": "QPVvqhIDYaJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN MODEL 1 TEST SIZE 0.3 Using 128 filters WITH 5 epoch\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# CNN model\n",
        "def get_model(input_shape):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(26, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for label, letter in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
        "    letter_dir = os.path.join('/content/BISINDO', letter)\n",
        "    for filename in os.listdir(letter_dir):\n",
        "        file_path = os.path.join(letter_dir, filename)\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        roi = cv2.resize(img, (64, 64))\n",
        "        X.append(roi)\n",
        "        y.append(label)\n",
        "\n",
        "# Convert the feature and label lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Reshape the training and testing sets to have 4 dimensions\n",
        "X_train = X_train.reshape(-1, 64, 64, 1)\n",
        "X_test = X_test.reshape(-1, 64, 64, 1)\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Create and train the CNN model\n",
        "model = get_model(X_train[0].shape)\n",
        "model.fit(X_train, y_train, epochs= 5)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "print('Precision: {:.2f}%'.format(precision * 100))\n",
        "print('Recall: {:.2f}%'.format(recall * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1 * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqPv-8sMX9Mh",
        "outputId": "4604191f-5126-4de7-9500-03ba95daef38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 7s 247ms/step - loss: 3.2100 - accuracy: 0.1008\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 5s 218ms/step - loss: 2.3552 - accuracy: 0.3450\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 6s 288ms/step - loss: 1.3353 - accuracy: 0.6122\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 5s 215ms/step - loss: 0.7311 - accuracy: 0.7908\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 5s 229ms/step - loss: 0.3467 - accuracy: 0.9099\n",
            "9/9 [==============================] - 1s 57ms/step\n",
            "Accuracy: 74.38%\n",
            "Precision: 79.89%\n",
            "Recall: 74.38%\n",
            "F1 score: 74.09%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN MODEL 1 TEST SIZE 0.3 Using 128 filters 15 Epoch\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# CNN model\n",
        "def get_model(input_shape):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(26, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for label, letter in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
        "    letter_dir = os.path.join('/content/BISINDO', letter)\n",
        "    for filename in os.listdir(letter_dir):\n",
        "        file_path = os.path.join(letter_dir, filename)\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        roi = cv2.resize(img, (64, 64))\n",
        "        X.append(roi)\n",
        "        y.append(label)\n",
        "\n",
        "# Convert the feature and label lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Reshape the training and testing sets to have 4 dimensions\n",
        "X_train = X_train.reshape(-1, 64, 64, 1)\n",
        "X_test = X_test.reshape(-1, 64, 64, 1)\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Create and train the CNN model\n",
        "model = get_model(X_train[0].shape)\n",
        "model.fit(X_train, y_train, epochs=15)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "print('Precision: {:.2f}%'.format(precision * 100))\n",
        "print('Recall: {:.2f}%'.format(recall * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1 * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNi9A7n3YDmE",
        "outputId": "b5eb28de-7576-468c-9dbe-520531234fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "21/21 [==============================] - 9s 350ms/step - loss: 3.2279 - accuracy: 0.0550\n",
            "Epoch 2/15\n",
            "21/21 [==============================] - 10s 505ms/step - loss: 2.4762 - accuracy: 0.3038\n",
            "Epoch 3/15\n",
            "21/21 [==============================] - 6s 274ms/step - loss: 1.3957 - accuracy: 0.5985\n",
            "Epoch 4/15\n",
            "21/21 [==============================] - 6s 279ms/step - loss: 0.7755 - accuracy: 0.7725\n",
            "Epoch 5/15\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.3859 - accuracy: 0.8885\n",
            "Epoch 6/15\n",
            "21/21 [==============================] - 5s 219ms/step - loss: 0.2276 - accuracy: 0.9328\n",
            "Epoch 7/15\n",
            "21/21 [==============================] - 6s 298ms/step - loss: 0.1180 - accuracy: 0.9695\n",
            "Epoch 8/15\n",
            "21/21 [==============================] - 5s 227ms/step - loss: 0.0309 - accuracy: 0.9969\n",
            "Epoch 9/15\n",
            "21/21 [==============================] - 6s 274ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 10/15\n",
            "21/21 [==============================] - 5s 243ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 11/15\n",
            "21/21 [==============================] - 5s 226ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "21/21 [==============================] - 6s 297ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "21/21 [==============================] - 5s 229ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "21/21 [==============================] - 6s 289ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "21/21 [==============================] - 5s 234ms/step - loss: 7.3148e-04 - accuracy: 1.0000\n",
            "9/9 [==============================] - 1s 97ms/step\n",
            "Accuracy: 82.56%\n",
            "Precision: 84.61%\n",
            "Recall: 82.56%\n",
            "F1 score: 82.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN MODEL 1 TEST SIZE 0.3 Using 128 filters with 25 epoch\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# CNN model\n",
        "def get_model(input_shape):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(26, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for label, letter in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
        "    letter_dir = os.path.join('/content/BISINDO', letter)\n",
        "    for filename in os.listdir(letter_dir):\n",
        "        file_path = os.path.join(letter_dir, filename)\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        roi = cv2.resize(img, (64, 64))\n",
        "        X.append(roi)\n",
        "        y.append(label)\n",
        "\n",
        "# Convert the feature and label lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Reshape the training and testing sets to have 4 dimensions\n",
        "X_train = X_train.reshape(-1, 64, 64, 1)\n",
        "X_test = X_test.reshape(-1, 64, 64, 1)\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Create and train the CNN model\n",
        "model = get_model(X_train[0].shape)\n",
        "model.fit(X_train, y_train, epochs=25)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "print('Precision: {:.2f}%'.format(precision * 100))\n",
        "print('Recall: {:.2f}%'.format(recall * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1 * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj8fSraEYD6S",
        "outputId": "5238b7f9-1922-45d5-fe9e-75587e713d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "21/21 [==============================] - 7s 278ms/step - loss: 3.2153 - accuracy: 0.0733\n",
            "Epoch 2/25\n",
            "21/21 [==============================] - 5s 216ms/step - loss: 2.5446 - accuracy: 0.2977\n",
            "Epoch 3/25\n",
            "21/21 [==============================] - 6s 291ms/step - loss: 1.4674 - accuracy: 0.5878\n",
            "Epoch 4/25\n",
            "21/21 [==============================] - 5s 215ms/step - loss: 0.6881 - accuracy: 0.7893\n",
            "Epoch 5/25\n",
            "21/21 [==============================] - 4s 214ms/step - loss: 0.3889 - accuracy: 0.8885\n",
            "Epoch 6/25\n",
            "21/21 [==============================] - 6s 288ms/step - loss: 0.1835 - accuracy: 0.9405\n",
            "Epoch 7/25\n",
            "21/21 [==============================] - 5s 216ms/step - loss: 0.1037 - accuracy: 0.9756\n",
            "Epoch 8/25\n",
            "21/21 [==============================] - 5s 255ms/step - loss: 0.0553 - accuracy: 0.9863\n",
            "Epoch 9/25\n",
            "21/21 [==============================] - 5s 236ms/step - loss: 0.0670 - accuracy: 0.9817\n",
            "Epoch 10/25\n",
            "21/21 [==============================] - 5s 233ms/step - loss: 0.0367 - accuracy: 0.9924\n",
            "Epoch 11/25\n",
            "21/21 [==============================] - 6s 289ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "21/21 [==============================] - 5s 217ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "21/21 [==============================] - 5s 233ms/step - loss: 8.2825e-04 - accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "21/21 [==============================] - 6s 262ms/step - loss: 6.3194e-04 - accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "21/21 [==============================] - 4s 214ms/step - loss: 5.3145e-04 - accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "21/21 [==============================] - 6s 289ms/step - loss: 4.4136e-04 - accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "21/21 [==============================] - 5s 263ms/step - loss: 3.8603e-04 - accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "21/21 [==============================] - 11s 532ms/step - loss: 3.3968e-04 - accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "21/21 [==============================] - 5s 231ms/step - loss: 3.0319e-04 - accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "21/21 [==============================] - 7s 352ms/step - loss: 2.7456e-04 - accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "21/21 [==============================] - 5s 237ms/step - loss: 2.4763e-04 - accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "21/21 [==============================] - 5s 227ms/step - loss: 2.2858e-04 - accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "21/21 [==============================] - 6s 278ms/step - loss: 2.0792e-04 - accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "21/21 [==============================] - 10s 488ms/step - loss: 1.9285e-04 - accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "21/21 [==============================] - 8s 359ms/step - loss: 1.8093e-04 - accuracy: 1.0000\n",
            "9/9 [==============================] - 1s 58ms/step\n",
            "Accuracy: 80.43%\n",
            "Precision: 82.53%\n",
            "Recall: 80.43%\n",
            "F1 score: 79.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# THIS IS THE EXPERIMENT PART OF THE NUMBER OF TEST SIZE"
      ],
      "metadata": {
        "id": "EO3p-V_QcPvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN MODEL 1 TEST SIZE 0.3(30%) Using 128 filters 15 Epoch\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# CNN model\n",
        "def get_model(input_shape):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(26, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for label, letter in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
        "    letter_dir = os.path.join('/content/BISINDO', letter)\n",
        "    for filename in os.listdir(letter_dir):\n",
        "        file_path = os.path.join(letter_dir, filename)\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        roi = cv2.resize(img, (64, 64))\n",
        "        X.append(roi)\n",
        "        y.append(label)\n",
        "\n",
        "# Convert the feature and label lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Reshape the training and testing sets to have 4 dimensions\n",
        "X_train = X_train.reshape(-1, 64, 64, 1)\n",
        "X_test = X_test.reshape(-1, 64, 64, 1)\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Create and train the CNN model\n",
        "model = get_model(X_train[0].shape)\n",
        "model.fit(X_train, y_train, epochs=15)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "print('Precision: {:.2f}%'.format(precision * 100))\n",
        "print('Recall: {:.2f}%'.format(recall * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1 * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58o4qyFEcUIX",
        "outputId": "e282086e-c73d-4a26-87b1-448fbacee1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "21/21 [==============================] - 9s 338ms/step - loss: 3.2159 - accuracy: 0.0855\n",
            "Epoch 2/15\n",
            "21/21 [==============================] - 11s 536ms/step - loss: 2.2818 - accuracy: 0.3817\n",
            "Epoch 3/15\n",
            "21/21 [==============================] - 11s 504ms/step - loss: 1.2139 - accuracy: 0.6443\n",
            "Epoch 4/15\n",
            "21/21 [==============================] - 8s 395ms/step - loss: 0.6652 - accuracy: 0.8168\n",
            "Epoch 5/15\n",
            "21/21 [==============================] - 7s 340ms/step - loss: 0.2932 - accuracy: 0.9130\n",
            "Epoch 6/15\n",
            "21/21 [==============================] - 6s 301ms/step - loss: 0.1167 - accuracy: 0.9679\n",
            "Epoch 7/15\n",
            "21/21 [==============================] - 6s 293ms/step - loss: 0.0673 - accuracy: 0.9802\n",
            "Epoch 8/15\n",
            "21/21 [==============================] - 5s 222ms/step - loss: 0.0493 - accuracy: 0.9817\n",
            "Epoch 9/15\n",
            "21/21 [==============================] - 5s 225ms/step - loss: 0.0166 - accuracy: 0.9969\n",
            "Epoch 10/15\n",
            "21/21 [==============================] - 6s 297ms/step - loss: 0.0129 - accuracy: 0.9969\n",
            "Epoch 11/15\n",
            "21/21 [==============================] - 5s 223ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "21/21 [==============================] - 6s 295ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "21/21 [==============================] - 5s 224ms/step - loss: 6.4281e-04 - accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "21/21 [==============================] - 5s 224ms/step - loss: 4.6690e-04 - accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "21/21 [==============================] - 6s 294ms/step - loss: 3.8866e-04 - accuracy: 1.0000\n",
            "9/9 [==============================] - 1s 61ms/step\n",
            "Accuracy: 83.27%\n",
            "Precision: 84.85%\n",
            "Recall: 83.27%\n",
            "F1 score: 82.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN MODEL 1 TEST SIZE 0.35 (35%) Using 128 filters 15 Epoch\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# CNN model\n",
        "def get_model(input_shape):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(26, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for label, letter in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
        "    letter_dir = os.path.join('/content/BISINDO', letter)\n",
        "    for filename in os.listdir(letter_dir):\n",
        "        file_path = os.path.join(letter_dir, filename)\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        roi = cv2.resize(img, (64, 64))\n",
        "        X.append(roi)\n",
        "        y.append(label)\n",
        "\n",
        "# Convert the feature and label lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n",
        "\n",
        "# Reshape the training and testing sets to have 4 dimensions\n",
        "X_train = X_train.reshape(-1, 64, 64, 1)\n",
        "X_test = X_test.reshape(-1, 64, 64, 1)\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Create and train the CNN model\n",
        "model = get_model(X_train[0].shape)\n",
        "model.fit(X_train, y_train, epochs=15)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "print('Precision: {:.2f}%'.format(precision * 100))\n",
        "print('Recall: {:.2f}%'.format(recall * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1 * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zugmeqAJcZ61",
        "outputId": "3f56f282-0a21-436c-8697-5994a8e0d6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "19/19 [==============================] - 6s 259ms/step - loss: 3.2487 - accuracy: 0.1365\n",
            "Epoch 2/15\n",
            "19/19 [==============================] - 5s 265ms/step - loss: 2.7155 - accuracy: 0.2549\n",
            "Epoch 3/15\n",
            "19/19 [==============================] - 5s 254ms/step - loss: 1.5310 - accuracy: 0.5773\n",
            "Epoch 4/15\n",
            "19/19 [==============================] - 6s 310ms/step - loss: 0.8903 - accuracy: 0.7549\n",
            "Epoch 5/15\n",
            "19/19 [==============================] - 4s 233ms/step - loss: 0.4405 - accuracy: 0.8717\n",
            "Epoch 6/15\n",
            "19/19 [==============================] - 5s 252ms/step - loss: 0.1876 - accuracy: 0.9490\n",
            "Epoch 7/15\n",
            "19/19 [==============================] - 6s 302ms/step - loss: 0.1132 - accuracy: 0.9638\n",
            "Epoch 8/15\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 0.0630 - accuracy: 0.9885\n",
            "Epoch 9/15\n",
            "19/19 [==============================] - 6s 303ms/step - loss: 0.0352 - accuracy: 0.9885\n",
            "Epoch 10/15\n",
            "19/19 [==============================] - 4s 223ms/step - loss: 0.0226 - accuracy: 0.9934\n",
            "Epoch 11/15\n",
            "19/19 [==============================] - 4s 238ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "19/19 [==============================] - 6s 319ms/step - loss: 0.0093 - accuracy: 0.9951\n",
            "Epoch 13/15\n",
            "19/19 [==============================] - 4s 229ms/step - loss: 0.0173 - accuracy: 0.9934\n",
            "Epoch 14/15\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 0.0262 - accuracy: 0.9951\n",
            "Epoch 15/15\n",
            "19/19 [==============================] - 6s 306ms/step - loss: 0.0337 - accuracy: 0.9868\n",
            "11/11 [==============================] - 1s 59ms/step\n",
            "Accuracy: 81.10%\n",
            "Precision: 83.82%\n",
            "Recall: 81.10%\n",
            "F1 score: 81.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN MODEL 1 TEST SIZE 0.4 (40%) Using 128 filters 15 Epoch\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# CNN model\n",
        "def get_model(input_shape):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(26, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for label, letter in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
        "    letter_dir = os.path.join('/content/BISINDO', letter)\n",
        "    for filename in os.listdir(letter_dir):\n",
        "        file_path = os.path.join(letter_dir, filename)\n",
        "        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        roi = cv2.resize(img, (64, 64))\n",
        "        X.append(roi)\n",
        "        y.append(label)\n",
        "\n",
        "# Convert the feature and label lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "# Reshape the training and testing sets to have 4 dimensions\n",
        "X_train = X_train.reshape(-1, 64, 64, 1)\n",
        "X_test = X_test.reshape(-1, 64, 64, 1)\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Create and train the CNN model\n",
        "model = get_model(X_train[0].shape)\n",
        "model.fit(X_train, y_train, epochs=15)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "print('Precision: {:.2f}%'.format(precision * 100))\n",
        "print('Recall: {:.2f}%'.format(recall * 100))\n",
        "print('F1 score: {:.2f}%'.format(f1 * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcmLZwP_canf",
        "outputId": "6554a325-7b36-443f-e323-37c5b800c8f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "18/18 [==============================] - 6s 223ms/step - loss: 3.2370 - accuracy: 0.0927\n",
            "Epoch 2/15\n",
            "18/18 [==============================] - 4s 229ms/step - loss: 2.7245 - accuracy: 0.2353\n",
            "Epoch 3/15\n",
            "18/18 [==============================] - 6s 313ms/step - loss: 1.7110 - accuracy: 0.5187\n",
            "Epoch 4/15\n",
            "18/18 [==============================] - 4s 228ms/step - loss: 1.0283 - accuracy: 0.7041\n",
            "Epoch 5/15\n",
            "18/18 [==============================] - 4s 232ms/step - loss: 0.5861 - accuracy: 0.8307\n",
            "Epoch 6/15\n",
            "18/18 [==============================] - 6s 314ms/step - loss: 0.3322 - accuracy: 0.9037\n",
            "Epoch 7/15\n",
            "18/18 [==============================] - 6s 339ms/step - loss: 0.1346 - accuracy: 0.9697\n",
            "Epoch 8/15\n",
            "18/18 [==============================] - 5s 279ms/step - loss: 0.0434 - accuracy: 0.9911\n",
            "Epoch 9/15\n",
            "18/18 [==============================] - 5s 250ms/step - loss: 0.0561 - accuracy: 0.9893\n",
            "Epoch 10/15\n",
            "18/18 [==============================] - 4s 251ms/step - loss: 0.0742 - accuracy: 0.9786\n",
            "Epoch 11/15\n",
            "18/18 [==============================] - 6s 312ms/step - loss: 0.0477 - accuracy: 0.9893\n",
            "Epoch 12/15\n",
            "18/18 [==============================] - 4s 226ms/step - loss: 0.0422 - accuracy: 0.9857\n",
            "Epoch 13/15\n",
            "18/18 [==============================] - 4s 229ms/step - loss: 0.0555 - accuracy: 0.9875\n",
            "Epoch 14/15\n",
            "18/18 [==============================] - 6s 311ms/step - loss: 0.0141 - accuracy: 0.9982\n",
            "Epoch 15/15\n",
            "18/18 [==============================] - 4s 228ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "12/12 [==============================] - 1s 60ms/step\n",
            "Accuracy: 81.87%\n",
            "Precision: 83.81%\n",
            "Recall: 81.87%\n",
            "F1 score: 81.52%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}